# üèóÔ∏è ARQUITETURA GOOGOLPLEX-BOOKS

**Sistema com 2 Pipelines Independentes para Processamento de Livros**

---

## üìê VIS√ÉO GERAL

```
FONTES ‚Üí DOWNLOAD ‚Üí VALIDA√á√ÉO ‚Üí TRADU√á√ÉO ‚Üí PIPELINE 1 (Completo PT)
                                          ‚Üì
                                     PIPELINE 2 (Bil√≠ngue PT+EN)
```

### Outputs Finais:
1. **Pipeline 1:** `docx/pipeline1/[Autor]/[Titulo]_pt.docx` - 100% portugu√™s + notas explicativas
2. **Pipeline 2:** `docx/pipeline2/[Autor]/[Titulo]_pt_bilingual.docx` - PT + 100 palavras EN + exemplos

---

## üîÑ FLUXO COMPLETO - PIPELINE 1

### ETAPA 1: DOWNLOAD
**Script:** `run_dual_hunter.py` (usa `hunter.py` + `hunter2.py`)

```
FONTES:
‚îú‚îÄ Project Gutenberg (70k livros)
‚îî‚îÄ Archive.org (40M livros)

ENTRADA: Query por idioma (en, es, ru, fr, de, it)
SA√çDA: txt/[idioma]/[Titulo]_[lang].txt
```

**Processo:**
1. Busca livros por idioma na fonte
2. Download do arquivo TXT
3. **Detec√ß√£o autom√°tica de idioma** (langdetect ou fallback)
4. **Adiciona sufixo:** `_en`, `_es`, `_pt`, `_ru`
5. Salva em `txt/[idioma]/[Titulo]_[lang].txt`

**Comando:**
```bash
python run_dual_hunter.py --languages en es --limit 50
```

---

### ETAPA 2: VALIDA√á√ÉO
**Script:** `run_dual_hunter.py` (valida√ß√£o integrada)

```
ENTRADA: txt/[idioma]/[Titulo]_[lang].txt
SA√çDA: V√°lido ‚Üí continua | Inv√°lido ‚Üí deleta + registra SQLite
```

**Crit√©rios de Valida√ß√£o:**
- Tamanho m√≠nimo: **5KB** (configur√°vel em `.env`)
- Encoding v√°lido: UTF-8, Latin-1, CP1252
- Conte√∫do m√≠nimo: 500 caracteres

**Se Inv√°lido:**
1. Arquivo √© deletado de `txt/`
2. Registro salvo em `data/invalid_files.db`:
   - Path original
   - Tamanho (bytes)
   - Motivo da invalida√ß√£o
   - Timestamp

**Comando para verificar inv√°lidos:**
```bash
sqlite3 data/invalid_files.db "SELECT * FROM invalid_files ORDER BY timestamp DESC"
```

---

### ETAPA 3: TRADU√á√ÉO
**Script:** `run_translator.py`

```
ENTRADA: txt/[idioma]/[Titulo]_[lang].txt (EN, ES, RU)
SA√çDA: translated/[Autor]/[Titulo]_pt.txt
```

**Processo:**
1. L√™ arquivo original em `txt/[idioma]/`
2. Divide em **chunks de 2000 caracteres**
3. Traduz para portugu√™s usando **Ollama LOCAL**
   - Modelo: `qwen2.5:32b` (configur√°vel)
   - Cache SQLite: `translation_cache.db`
   - Evita retradu√ß√£o de chunks j√° processados
4. Reconstr√≥i texto completo traduzido
5. Salva em `translated/[Autor]/[Titulo]_pt.txt`

**Configura√ß√£o (.env):**
```env
OLLAMA_MODEL=qwen2.5:32b
OLLAMA_BASE_URL=http://localhost:11434
MAX_CHUNK_TOKENS=2000
TEMPERATURE=0.2
```

**Comando:**
```bash
python run_translator.py --languages en es --limit 10
```

---

### ETAPA 4: CORRE√á√ÉO + IDENTIFICA√á√ÉO DE NOTAS
**Script:** `run_processor.py` (usa `src/processor.py`)

```
ENTRADA: translated/[Autor]/[Titulo]_pt.txt
SA√çDA: docx/pipeline1/[Autor]/[Titulo]_pt.docx
```

**Processo:**

#### 4.1 CORRE√á√ÉO DE TEXTO
- Corrige gram√°tica e ortografia
- Corrige erros de OCR comuns:
  - `rn` ‚Üí `m`
  - `cl` ‚Üí `d`
  - `l` ‚Üí `i`
  - Espa√ßos incorretos
- Mant√©m estrutura de par√°grafos
- Cache: `cache.db`

#### 4.2 IDENTIFICA√á√ÉO DE TERMOS IMPORTANTES
**IA identifica automaticamente:**
- ‚úÖ Palavras estrangeiras (√úbermensch, carpe diem, etc.)
- ‚úÖ Nomes pr√≥prios pouco conhecidos
- ‚úÖ Termos t√©cnicos complexos
- ‚úÖ Cita√ß√µes e refer√™ncias

**Formato de marca√ß√£o:**
```
[NOTA:termo|explica√ß√£o breve]
```

**Exemplo:**
```
Texto: "o conceito de √úbermensch mudou a filosofia"
       ‚Üì
Marcado: "o conceito de [NOTA:√úbermensch|Super-homem, conceito de Nietzsche sobre o homem ideal] mudou a filosofia"
```

#### 4.3 EXTRA√á√ÉO DE NOTAS
- Extrai marcadores `[NOTA:...|...]`
- Gera refer√™ncias `[1]`, `[2]`, etc.
- Cria lista de notas de rodap√©

#### 4.4 GERA√á√ÉO DOCX
- Aplica template KDP (`Estrutura.docx`)
- Formata par√°grafos (justificado, espa√ßamento)
- Detecta cap√≠tulos (mai√∫sculas, centralizado)
- Adiciona notas de rodap√© ao final
- Numera√ß√£o de p√°ginas

**Comando:**
```bash
# Arquivo espec√≠fico
python run_processor.py --input translated/Autor/Livro_pt.txt --author "Nome Autor"

# Batch (todos arquivos em translated/)
python run_processor.py --batch
```

---

## üîÑ FLUXO COMPLETO - PIPELINE 2

### OBJETIVO
Gerar vers√£o **bil√≠ngue** para **aprendizado de ingl√™s** usando **semantic priming**.

```
ENTRADA: translated/[Autor]/[Titulo]_pt.txt
SA√çDA: docx/pipeline2/[Autor]/[Titulo]_pt_bilingual.docx
```

---

### ETAPA 1: AN√ÅLISE DE FREQU√äNCIA
**Script:** `processor_bilingual.py` (a ser criado)

**Processo:**
1. L√™ texto traduzido em portugu√™s
2. Tokeniza√ß√£o (palavras)
3. Remove stop words (artigos, preposi√ß√µes, conjun√ß√µes)
4. Aplica **TF-IDF** (Term Frequency-Inverse Document Frequency)
5. Identifica palavras mais relevantes:
   - Verbos importantes
   - Substantivos-chave
   - Adjetivos significativos

**Exemplo de stop words removidas:**
```
PT: o, a, de, e, que, do, da, em, um, para, √©, com, n√£o, por, mais...
```

---

### ETAPA 2: SEMANTIC CLUSTERING
**Objetivo:** Agrupar palavras semanticamente relacionadas.

**T√©cnica:**
1. **Word Embeddings:** Usa modelo pr√©-treinado
   - Op√ß√£o 1: Word2Vec
   - Op√ß√£o 2: BERT/sentence-transformers
   - Op√ß√£o 3: spaCy
2. **C√°lculo de similaridade:** Cosine similarity entre vetores
3. **Clustering:** K-means (~10-15 clusters)

**Exemplo de Cluster Sem√¢ntico:**
```
CLUSTER "REALEZA":
‚îú‚îÄ king (rei)
‚îú‚îÄ kingdom (reino)
‚îú‚îÄ queen (rainha)
‚îú‚îÄ throne (trono)
‚îú‚îÄ crown (coroa)
‚îî‚îÄ palace (pal√°cio)
```

**Prioriza√ß√£o:**
- Palavras em clusters densos (alta co-ocorr√™ncia)
- Palavras centrais (mais conex√µes sem√¢nticas)
- Alta frequ√™ncia no texto

---

### ETAPA 3: SELE√á√ÉO DE 100 PALAVRAS
**Crit√©rios:**
1. Alta relev√¢ncia (TF-IDF score)
2. **Prioridade para palavras com priming sem√¢ntico**
3. Exclus√£o de:
   - Stop words
   - Palavras muito simples (1-2 letras)
   - N√∫meros isolados
4. Balanceamento:
   - ~40-50% substantivos
   - ~30-40% verbos
   - ~10-20% adjetivos
   - ~5-10% adv√©rbios

**Sele√ß√£o com Semantic Priming:**
```
Exemplo: Se "king" est√° na lista:
  ‚Üí Aumenta score de: kingdom, queen, throne, royal
  ‚Üí Se alguma dessas j√° tem TF-IDF alto ‚Üí entra na lista
```

---

### ETAPA 4: TRADU√á√ÉO DAS 100 PALAVRAS
**Processo:**
1. Pega as 100 palavras selecionadas (em PT)
2. Traduz para ingl√™s (dicion√°rio ou API)
3. Cria mapeamento: `{palavra_pt: palavra_en}`

**Exemplo:**
```python
{
  "rei": "king",
  "reino": "kingdom",
  "rainha": "queen",
  "decis√£o": "decision",
  "importante": "important"
}
```

---

### ETAPA 5: SUBSTITUI√á√ÉO NO TEXTO
**Processo:**
1. Varre texto em portugu√™s
2. Substitui as 100 palavras selecionadas por suas vers√µes em ingl√™s
3. Adiciona marcador de nota: `[1]`, `[2]`, etc.

**IMPORTANTE - Preserva√ß√£o de Contexto:**
- Mant√©m conjuga√ß√µes e concord√¢ncias em portugu√™s
- S√≥ substitui a palavra-raiz
- N√£o quebra estrutura de frases

**Exemplo de Substitui√ß√£o:**
```
ANTES:
"O rei vivia em seu grande reino com a rainha"

DEPOIS:
"O king[1] vivia em seu grande kingdom[2] com a queen[3]"
```

---

### ETAPA 6: GERA√á√ÉO DE 3 FRASES EXEMPLO
**Para cada uma das 100 palavras:**

**Processo:**
1. Gera 3 frases em **ingl√™s** usando a palavra
2. Frases devem ser:
   - Simples e claras
   - Contextualizadas (n√£o gen√©ricas)
   - Variadas (diferentes contextos)
   - 8-15 palavras cada

**Exemplo para "king":**
```
[1] king (PT: rei)
    ‚Ä¢ The king ruled for 40 years.
    ‚Ä¢ He became king at age 21.
    ‚Ä¢ A wise king makes good decisions.
```

**Gera√ß√£o via IA:**
- Prompt ao Ollama: "Generate 3 simple English example sentences using the word 'king'"
- Valida√ß√£o: tamanho, clareza, varia√ß√£o

---

### ETAPA 7: GERA√á√ÉO DOCX BIL√çNGUE
**Formato Final:**

```
TEXTO BIL√çNGUE:
"O king[1] tomou uma importante decision[2] sobre o futuro do kingdom[3].
A queen[4] apoiou a escolha do king[1]."

NOTAS DE RODAP√â:

[1] king (PT: rei)
    ‚Ä¢ The king ruled for 40 years.
    ‚Ä¢ He became king at age 21.
    ‚Ä¢ A wise king makes good decisions.

[2] decision (PT: decis√£o)
    ‚Ä¢ That was a difficult decision.
    ‚Ä¢ We need to make a decision soon.
    ‚Ä¢ Her decision changed everything.

[3] kingdom (PT: reino)
    ‚Ä¢ The kingdom was very large.
    ‚Ä¢ He inherited the kingdom from his father.
    ‚Ä¢ A prosperous kingdom needs good governance.

[4] queen (PT: rainha)
    ‚Ä¢ The queen addressed her people.
    ‚Ä¢ She became queen in 1952.
    ‚Ä¢ The queen and king ruled together.
```

**Formata√ß√£o:**
- Template KDP (`Estrutura.docx`)
- Texto bil√≠ngue justificado
- Refer√™ncias sobrescritas `[N]`
- Se√ß√£o de notas ao final
- Numera√ß√£o de p√°ginas

**Comando:**
```bash
# Arquivo espec√≠fico
python run_processor_bilingual.py --input docx/pipeline1/Autor/Livro_pt.docx

# Batch (todos DOCX do Pipeline 1)
python run_processor_bilingual.py --batch
```

---

## üìä COMPARA√á√ÉO DOS PIPELINES

| **Aspecto** | **Pipeline 1** | **Pipeline 2** |
|-------------|----------------|----------------|
| **Entrada** | `translated/[Autor]/[Titulo]_pt.txt` | `translated/[Autor]/[Titulo]_pt.txt` |
| **Idioma do texto** | 100% Portugu√™s | PT + 100 palavras EN |
| **Notas de rodap√©** | Termos t√©cnicos explicados | 100 palavras EN + 3 frases exemplo |
| **Objetivo** | Leitura fluida em PT | Aprendizado de ingl√™s |
| **P√∫blico-alvo** | Leitores gerais | Estudantes de ingl√™s |
| **T√©cnica especial** | Identifica√ß√£o autom√°tica de termos | **Semantic Priming** |
| **Arquivo de sa√≠da** | `[Titulo]_pt.docx` | `[Titulo]_pt_bilingual.docx` |
| **Pasta de sa√≠da** | `docx/pipeline1/[Autor]/` | `docx/pipeline2/[Autor]/` |
| **Template** | `Estrutura.docx` | `Estrutura.docx` |

---

## üéØ SEMANTIC PRIMING - DETALHES

### O que √©?
T√©cnica de aprendizado onde palavras **semanticamente relacionadas** s√£o agrupadas para facilitar memoriza√ß√£o.

### Exemplo Pr√°tico:
```
Cluster ANIMAIS:
"O gato[1] viu o cachorro[2] e subiu na √°rvore"

Notas:
[1] cat (PT: gato)
    ‚Ä¢ The cat is sleeping.
    ‚Ä¢ I have a black cat.
    ‚Ä¢ Cats love to climb trees.

[2] dog (PT: cachorro)
    ‚Ä¢ The dog barks loudly.
    ‚Ä¢ My dog is very friendly.
    ‚Ä¢ Dogs are loyal animals.
```

### Por que funciona?
- **Ativa√ß√£o cruzada:** Aprender "king" ativa neur√¥nios de "kingdom", "queen"
- **Contexto compartilhado:** Palavras aparecem pr√≥ximas no texto
- **Refor√ßo m√∫tuo:** Revisar uma palavra refor√ßa palavras relacionadas

---

## üìÇ ESTRUTURA DE ARQUIVOS

```
Googolplex-Books/
‚îú‚îÄ‚îÄ txt/                                    # Livros originais
‚îÇ   ‚îú‚îÄ‚îÄ en/                                 # 1.722 livros ingl√™s
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_en.txt
‚îÇ   ‚îú‚îÄ‚îÄ es/                                 # 214 livros espanhol
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_es.txt
‚îÇ   ‚îú‚îÄ‚îÄ pt/                                 # 236 livros portugu√™s
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_pt.txt
‚îÇ   ‚îú‚îÄ‚îÄ ru/                                 # 1.294 livros russo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_ru.txt
‚îÇ   ‚îî‚îÄ‚îÄ unknown/                            # 12 livros (idioma n√£o detectado)
‚îÇ
‚îú‚îÄ‚îÄ translated/[Autor]/                     # Livros traduzidos
‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_pt.txt                     # Portugu√™s (sem corre√ß√£o)
‚îÇ
‚îú‚îÄ‚îÄ docx/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline1/[Autor]/                  # DOCX Pipeline 1
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [Titulo]_pt.docx                # PT completo + notas explicativas
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ pipeline2/[Autor]/                  # DOCX Pipeline 2
‚îÇ       ‚îî‚îÄ‚îÄ [Titulo]_pt_bilingual.docx      # PT + 100 palavras EN + exemplos
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ books.db                            # Registro de livros
‚îÇ   ‚îú‚îÄ‚îÄ translation_cache.db                # Cache de tradu√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ cache.db                            # Cache de corre√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ invalid_files.db                    # Arquivos inv√°lidos
‚îÇ
‚îú‚îÄ‚îÄ logs/                                   # Logs de execu√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ src/                                    # C√≥digo fonte
‚îÇ   ‚îú‚îÄ‚îÄ hunter.py                           # Download Gutenberg
‚îÇ   ‚îú‚îÄ‚îÄ hunter2.py                          # Download Archive.org
‚îÇ   ‚îú‚îÄ‚îÄ processor.py                        # Pipeline 1
‚îÇ   ‚îú‚îÄ‚îÄ processor_bilingual.py              # Pipeline 2 (A CRIAR)
‚îÇ   ‚îî‚îÄ‚îÄ database.py                         # Gerenciamento SQLite
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                         # Configura√ß√µes centralizadas
‚îÇ
‚îú‚îÄ‚îÄ run_daemon.py                           # Daemon 24/7 (orquestra tudo)
‚îú‚îÄ‚îÄ run_dual_hunter.py                      # Download + valida√ß√£o
‚îú‚îÄ‚îÄ run_translator.py                       # Tradu√ß√£o EN/ES/RU ‚Üí PT
‚îú‚îÄ‚îÄ run_processor.py                        # Pipeline 1
‚îú‚îÄ‚îÄ run_processor_bilingual.py              # Pipeline 2 (A CRIAR)
‚îÇ
‚îú‚îÄ‚îÄ Estrutura.docx                          # Template KDP
‚îî‚îÄ‚îÄ .env                                    # Configura√ß√µes
```

---

## ‚öôÔ∏è CONFIGURA√á√ÉO (.env)

```env
# ============================================================================
# OLLAMA (IA LOCAL)
# ============================================================================
MODEL_BACKEND=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:32b

# ============================================================================
# PROCESSAMENTO
# ============================================================================
MAX_CHUNK_TOKENS=2000          # Tamanho de chunk para tradu√ß√£o
MAX_OUTPUT_TOKENS=8192         # M√°ximo de tokens na resposta
TEMPERATURE=0.2                # Criatividade (0.0-1.0)
PARALLEL_CHUNKS=4              # Chunks processados em paralelo

# ============================================================================
# VALIDA√á√ÉO
# ============================================================================
MIN_FILE_SIZE=5000             # Tamanho m√≠nimo em bytes (5KB)

# ============================================================================
# SEMANTIC CLUSTERING (Pipeline 2)
# ============================================================================
NUM_KEYWORDS=100               # N√∫mero de palavras-chave
NUM_CLUSTERS=12                # N√∫mero de clusters sem√¢nticos
NUM_EXAMPLES=3                 # Frases exemplo por palavra
```

---

## üöÄ COMANDOS DE EXECU√á√ÉO

### 1. Download + Valida√ß√£o
```bash
# Baixar 50 livros em EN e ES de ambas as fontes
python run_dual_hunter.py --languages en es --limit 50

# Apenas Gutenberg
python run_dual_hunter.py --languages en --limit 100 --skip-archive

# Apenas Archive.org
python run_dual_hunter.py --languages en --limit 100 --skip-gutenberg
```

### 2. Tradu√ß√£o
```bash
# Traduzir livros em EN e ES para PT
python run_translator.py --languages en es --limit 10

# Traduzir TODOS os livros n√£o traduzidos
python run_translator.py --languages en es ru
```

### 3. Pipeline 1 (Tradu√ß√£o Completa)
```bash
# Processar arquivo espec√≠fico
python run_processor.py --input translated/Autor/Livro_pt.txt --author "Nome"

# Processar todos arquivos em translated/
python run_processor.py --batch
```

### 4. Pipeline 2 (Bil√≠ngue + Semantic Priming)
```bash
# Processar arquivo espec√≠fico
python run_processor_bilingual.py --input translated/Autor/Livro_pt.txt

# Processar todos DOCX do Pipeline 1
python run_processor_bilingual.py --batch
```

### 5. Daemon Completo (24/7)
```bash
# Executa tudo automaticamente
python run_daemon.py --languages en es --batch-size 50
```

---

## üìà PERFORMANCE ESTIMADA

| **Etapa** | **Velocidade** | **Tempo para 50 livros** |
|-----------|----------------|--------------------------|
| Download | ~100 livros/10min | 5 minutos |
| Tradu√ß√£o | ~6-8 livros/dia | ~7 dias |
| Pipeline 1 | ~10-15 DOCX/hora | 3-5 horas |
| Pipeline 2 | ~8-12 DOCX/hora | 4-6 horas |
| **TOTAL** | - | **~8-9 dias** |

**Hardware recomendado:**
- CPU: 8+ cores
- RAM: 32GB+
- GPU: N√£o necess√°ria (Ollama usa CPU)
- Disco: 50GB+ livre

---

## üîç VALIDA√á√ÉO E QUALIDADE

### Valida√ß√£o de Arquivos
```bash
# Ver arquivos inv√°lidos
sqlite3 data/invalid_files.db "SELECT * FROM invalid_files ORDER BY timestamp DESC LIMIT 10"

# Estat√≠sticas
sqlite3 data/invalid_files.db "SELECT COUNT(*) FROM invalid_files"
```

### Cache
```bash
# Ver tradu√ß√µes em cache
sqlite3 data/translation_cache.db "SELECT COUNT(*) FROM translations"

# Ver corre√ß√µes em cache
sqlite3 data/cache.db "SELECT COUNT(*) FROM corrections"
```

### Logs
```bash
# Ver logs em tempo real
tail -f logs/daemon_20260207.log

# Buscar erros
grep ERROR logs/*.log
```

---

## üìù PR√ìXIMOS PASSOS

- [x] 1. Organizar todos TXT com sufixo de idioma
- [x] 2. Organizar TXT em subpastas por idioma (txt/en/, txt/es/, etc.)
- [x] 3. Implementar valida√ß√£o de arquivos + SQLite
- [ ] 4. Criar `processor_bilingual.py` (Pipeline 2)
- [ ] 5. Implementar an√°lise TF-IDF para palavras-chave
- [ ] 6. Implementar semantic clustering (Word2Vec/BERT)
- [ ] 7. Implementar gera√ß√£o de 3 frases exemplo
- [ ] 8. Testar Pipeline 2 com livros pequenos
- [ ] 9. Otimizar para processamento em lote
- [ ] 10. Aguardar download modelo `qwen2.5:32b`

---

**√öltima atualiza√ß√£o:** 2026-02-07
**Vers√£o:** 4.0 (2 Pipelines + Semantic Priming)
**Status:** Aguardando modelo Ollama
